# Milestone 8: Dimensions

**Started:** Feb 4, 2026 | **Status:** in progress

- [ ] edit dimensions -> renders the change
- [ ] tweaks to assure that dimensionals extend outward from SO

## Goal

Render 3 dimensionals. Then make them editable — changing a dimension value updates the geometry.

A dimensional is a decoration attached to an edge, containing: terminator arrows, dimension text, dimension lines, witness lines.

Geometry SOT (source of truth) is SO (three axes, each has size and position relative to origin). O_Scene accesses the SOT and renders in reaction. User interacts with the 2D projection displayed on the camera.

Each edge is parallel to three others around the SO. Algorithm A selects one as the attached edge. Each edge belongs to two faces. Algorithm B selects which face's plane to draw the witness lines in. When the chosen edge is pointing towards the camera, the text gets occluded by the witness and dimension lines, Algorithm C detects this and either inverts the dimension lines and arrows or hides the entire dimensional.

### Algorithm A — edge selection

Silhouette edge detection. A silhouette edge has one front-facing and one back-facing adjacent face. For each axis, there are always exactly 2 silhouette edges; prefer the one whose front-facing adjacent face is most toward the viewer (most negative winding).

- [x] must be on the circumference — not the edge that is in front
- [x] there will always be two such, prefer the front
- [x] if the projected witness lines are too close for the text, hide the dimensional

### Algorithm B — witness plane

Pick the witness direction most perpendicular to the edge on screen. Project each candidate axis (the two perpendicular to the edge axis) to screen, compute cross product with the edge's screen direction. The candidate with the largest cross product magnitude wins.

- [x] optimizes directly for visual spread via screen-space perpendicularity
- [x] handles edge cases where face normal · camera gives poor results

### Algorithm C — crunch detection

When the chosen edge is pointing towards the camera, the text gets occluded by the witness and dimension lines, detect this and either invert the dimension lines and arrows or hide the entire dimensional.

The "gap" needed for text is not the text's pixel width — it's the distance the dimension line travels across the text's bounding box:

```
gap = textWidth * |ux| + textHeight * |uy| + padding
```

Where `(ux, uy)` is the unit vector along the dimension line.

- [x] compute gap using projected text bounding box onto dimension line direction
- [x] if `lineLen >= gap + arrows`: normal layout (text centered, arrows at ends pointing in)
- [x] if `lineLen >= gap` but `< gap + arrows`: inverted layout (arrows outside, pointing in toward text)
- [x] if `lineLen < gap`: hide the dimensional (including witness lines)

---

## Work Phases

- [x] 1 draw the dimensionals, algorithms A and B
- [x] 2 stretch the SO → dimensionals react
- [ ] 3 edit the text → SO reacts

### Implement

- [x] dimension data structure (derived on render, no persistent state)
- [x] witness lines (3D-projected, perpendicular to measured edge)
- [x] dimension line (parallel, between witnesses, with text gap)
- [x] terminator arrows
- [x] dimension text (value centered on dimension line)
- [x] Algorithm A — silhouette edge detection
- [x] Algorithm B — witness plane via screen-space perpendicularity
- [x] Algorithm C — crunch detection with projected text gap
- [ ] edit interaction (click text, type value, apply)

### Test manually

- [x] shows 3 dimensions (one per axis), always
- [x] dimensions update when geometry dragged
- [ ] edit dimension value — geometry resizes accordingly

---

## Artifacts

- `Render.ts` — `render_dimensions`, `render_axis_dimension`, `find_best_edge_for_axis`, `edge_witness_direction`, `draw_dimension_3d`

## Key Decisions

- dimensions are derived on render (no persistent data structure) — YAGNI
- Algorithm A uses silhouette edges, not front-face + distance-from-center heuristic
- Algorithm B uses screen-space perpendicularity (cross product), not face normal · camera or projected length
- Algorithm C uses projected text bounding box for gap calculation, not raw text width
